### Introduction
The computer vision community is actively researching the ability to recognise human action from video. In this project, Python is used to create a prototype model for recognising human action from video

### Built With
Python

### Dataset
KTH dataset comprises the videos of human actions boxing, handclapping, hand waving, jogging, running, and walking performed by six different people. These acts are carried out by 25 individuals in 4 settings: inside, outdoor with scale variation, outdoor with various clothing, and outdoor. Therefore, 25x4x6 = 600 videos make up the entire collection. The videos have a frame rate of 25 frames per second and a 160x120 resolution. On the website, you may check for more details about the dataset.[https://www.csc.kth.se/cvap/actions/]
